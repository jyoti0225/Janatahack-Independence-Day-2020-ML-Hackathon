{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQC_smbmZ7ER"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, Conv2D, MaxPooling1D, Dropout, Activation,GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "A5vj0y2FmVrV",
    "outputId": "70ceaf34-87ec-4e5e-fc58-5a854b3cecfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "2PX3kyAHj7Mu",
    "outputId": "341bd6b7-ecb5-405b-abbb-cd98aad108fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rotation Invariance Neural Network   Rotation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  ...                                             merged\n",
       "0                 1  ...  Reconstructing Subject-Specific Effect Maps   ...\n",
       "1                 1  ...  Rotation Invariance Neural Network   Rotation ...\n",
       "2                 0  ...  Spherical polyharmonics and Poisson kernels fo...\n",
       "3                 0  ...  A finite element approximation for the stochas...\n",
       "4                 1  ...  Comparative study of Discrete Wavelet Transfor...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "lemma=WordNetLemmatizer()\n",
    "token=ToktokTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "df['merged'] = df['TITLE']+\" \" + df['ABSTRACT']\n",
    "df.drop(['ID','TITLE','ABSTRACT'], inplace = True, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "op2cXEExj7JY"
   },
   "outputs": [],
   "source": [
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "def lemitizeWords(text):\n",
    "    words=token.tokenize(text)\n",
    "    listLemma=[]\n",
    "    for w in words:\n",
    "        x=lemma.lemmatize(w,'v')\n",
    "        listLemma.append(x)\n",
    "        listLemma.append(\" \")\n",
    "    return ''.join(listLemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iubNmSxj7Gp"
   },
   "outputs": [],
   "source": [
    "def PreProcessing(text):\n",
    "    text=clean_text(text)\n",
    "    text=remove_stopwords(text)\n",
    "    # text=lemitizeWords(text)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "FAtO6VQEkygs",
    "outputId": "59e0c040-cfd8-4a00-d480-12f6291333ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reconstructing subject specific effect maps pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rotation invariance neural network rotation in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spherical polyharmonics poisson kernels polyha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>finite element approximation stochastic maxwel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>comparative study discrete wavelet transforms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  ...                                             merged\n",
       "0                 1  ...  reconstructing subject specific effect maps pr...\n",
       "1                 1  ...  rotation invariance neural network rotation in...\n",
       "2                 0  ...  spherical polyharmonics poisson kernels polyha...\n",
       "3                 0  ...  finite element approximation stochastic maxwel...\n",
       "4                 1  ...  comparative study discrete wavelet transforms ...\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['merged'] = df['merged'].apply(lambda com : PreProcessing(com))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vnsfDIURkycH",
    "outputId": "97ea6c20-f49b-4cf2-8ce5-7823885a8bb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  Physics  ...  Quantitative Biology  Quantitative Finance\n",
       "0                 1        0  ...                     0                     0\n",
       "1                 1        0  ...                     0                     0\n",
       "2                 0        0  ...                     0                     0\n",
       "3                 0        0  ...                     0                     0\n",
       "4                 1        0  ...                     0                     0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,0:6]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "SqjtfzjFk_Gf",
    "outputId": "a549e246-3c61-4997-b775-593cffbdf659"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reconstructing subject specific effect maps pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rotation invariance neural network rotation in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spherical polyharmonics poisson kernels polyha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finite element approximation stochastic maxwel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comparative study discrete wavelet transforms ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              merged\n",
       "0  reconstructing subject specific effect maps pr...\n",
       "1  rotation invariance neural network rotation in...\n",
       "2  spherical polyharmonics poisson kernels polyha...\n",
       "3  finite element approximation stochastic maxwel...\n",
       "4  comparative study discrete wavelet transforms ..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.iloc[:,6:]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ByO5-Qx5X28N"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(df_new['merged'], y, test_size=0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQMcBNS0YHfW"
   },
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.9, max_features=300000, smooth_idf=True,use_idf=True,ngram_range=(1,3),dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpuZICPHX24G"
   },
   "outputs": [],
   "source": [
    "# # create TF-IDF features\n",
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_val_tfidf = tfidf_vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n31YDHkSgcHY"
   },
   "outputs": [],
   "source": [
    "# #Using CountVectorizer\n",
    "# countvector = CountVectorizer(ngram_range=(1,2))\n",
    "# X_train_cv = countvector.fit_transform(x_train)\n",
    "# X_test_cv = countvector.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2cT4OJRgcDB"
   },
   "outputs": [],
   "source": [
    "# #Using TfidfVectorizer\n",
    "# tfidfvector = TfidfTransformer()\n",
    "# X_train_tf = tfidfvector.fit_transform(X_train_cv)\n",
    "# X_test_tf = tfidfvector.fit_transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dntyDpmNVZvO"
   },
   "outputs": [],
   "source": [
    "from keras.layers import  Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def TFIDF(X_train, X_test,MAX_NB_WORDS=300000):\n",
    "    vectorizer_x = TfidfVectorizer(max_features=MAX_NB_WORDS,max_df=0.9, smooth_idf=True,use_idf=True,ngram_range=(1,3),dtype=np.float32)\n",
    "    X_train = vectorizer_x.fit_transform(X_train)\n",
    "    X_test = vectorizer_x.transform(X_test)\n",
    "    return (X_train,X_test)\n",
    "\n",
    "def Build_Model_DNN_Text(shape, nClasses, dropout=0.1):\n",
    "    \"\"\"\n",
    "    buildModel_DNN_Tex(shape, nClasses,dropout)\n",
    "    Build Deep neural networks Model for text classification\n",
    "    Shape is input feature space\n",
    "    nClasses is number of classes\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    node = 1024 # number of nodes\n",
    "    nLayers = 4 # number of  hidden layer\n",
    "\n",
    "    model.add(Dense(node,input_dim=shape,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(216,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(nClasses, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JSKRJF0vSDP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
    "\n",
    "y_train = tf.convert_to_tensor(y_train, bool)\n",
    "y_val = tf.convert_to_tensor(y_val, bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "VA_lEmJUVZsd",
    "outputId": "224547a4-5fa9-4b84-c0a2-8f16994a3a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              307201024 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 216)               110808    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               27776     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 307,874,942\n",
      "Trainable params: 307,874,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf,X_test_tfidf = TFIDF(x_train,x_val)\n",
    "\n",
    "model_DNN = Build_Model_DNN_Text(X_train_tfidf.shape[1], 6)\n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c3tQbmXJ2VhE",
    "outputId": "0d0f9078-1549-406b-c4c5-b2b2f70dc030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 - 141s - loss: 0.3298 - accuracy: 0.5886 - val_loss: 0.1896 - val_accuracy: 0.7459\n",
      "Epoch 2/50\n",
      "148/148 - 140s - loss: 0.1386 - accuracy: 0.7927 - val_loss: 0.1885 - val_accuracy: 0.7660\n",
      "Epoch 3/50\n",
      "148/148 - 139s - loss: 0.0583 - accuracy: 0.8416 - val_loss: 0.2470 - val_accuracy: 0.7631\n",
      "Epoch 4/50\n",
      "148/148 - 139s - loss: 0.0303 - accuracy: 0.8668 - val_loss: 0.3136 - val_accuracy: 0.7769\n",
      "Epoch 5/50\n",
      "148/148 - 140s - loss: 0.0154 - accuracy: 0.8710 - val_loss: 0.3609 - val_accuracy: 0.7836\n",
      "Epoch 6/50\n",
      "148/148 - 139s - loss: 0.0100 - accuracy: 0.8595 - val_loss: 0.3879 - val_accuracy: 0.7626\n",
      "Epoch 7/50\n",
      "148/148 - 139s - loss: 0.0080 - accuracy: 0.8662 - val_loss: 0.4365 - val_accuracy: 0.7660\n",
      "Epoch 8/50\n",
      "148/148 - 139s - loss: 0.0056 - accuracy: 0.8635 - val_loss: 0.4589 - val_accuracy: 0.7812\n",
      "Epoch 9/50\n",
      "148/148 - 140s - loss: 0.0052 - accuracy: 0.8585 - val_loss: 0.4467 - val_accuracy: 0.7531\n",
      "Epoch 10/50\n",
      "148/148 - 139s - loss: 0.0045 - accuracy: 0.8681 - val_loss: 0.4770 - val_accuracy: 0.7398\n",
      "Epoch 11/50\n",
      "148/148 - 139s - loss: 0.0045 - accuracy: 0.8483 - val_loss: 0.4436 - val_accuracy: 0.7393\n",
      "Epoch 12/50\n",
      "148/148 - 138s - loss: 0.0040 - accuracy: 0.8431 - val_loss: 0.4665 - val_accuracy: 0.7440\n",
      "Epoch 13/50\n",
      "148/148 - 139s - loss: 0.0031 - accuracy: 0.8430 - val_loss: 0.4595 - val_accuracy: 0.7378\n",
      "Epoch 14/50\n",
      "148/148 - 138s - loss: 0.0024 - accuracy: 0.8322 - val_loss: 0.4908 - val_accuracy: 0.7431\n",
      "Epoch 15/50\n",
      "148/148 - 139s - loss: 0.0026 - accuracy: 0.8330 - val_loss: 0.4539 - val_accuracy: 0.7536\n",
      "Epoch 16/50\n",
      "148/148 - 141s - loss: 0.0025 - accuracy: 0.8468 - val_loss: 0.5012 - val_accuracy: 0.7164\n",
      "Epoch 17/50\n",
      "148/148 - 141s - loss: 0.0025 - accuracy: 0.8564 - val_loss: 0.4974 - val_accuracy: 0.7259\n",
      "Epoch 18/50\n",
      "148/148 - 141s - loss: 0.0026 - accuracy: 0.8494 - val_loss: 0.5164 - val_accuracy: 0.7412\n",
      "Epoch 19/50\n",
      "148/148 - 140s - loss: 0.0022 - accuracy: 0.8544 - val_loss: 0.5249 - val_accuracy: 0.7712\n",
      "Epoch 20/50\n",
      "148/148 - 140s - loss: 0.0025 - accuracy: 0.8618 - val_loss: 0.4957 - val_accuracy: 0.7526\n",
      "Epoch 21/50\n",
      "148/148 - 140s - loss: 0.0011 - accuracy: 0.8522 - val_loss: 0.5674 - val_accuracy: 0.7545\n",
      "Epoch 22/50\n",
      "148/148 - 140s - loss: 0.0018 - accuracy: 0.8697 - val_loss: 0.5647 - val_accuracy: 0.7431\n",
      "Epoch 23/50\n",
      "148/148 - 140s - loss: 0.0011 - accuracy: 0.8607 - val_loss: 0.5718 - val_accuracy: 0.7574\n",
      "Epoch 24/50\n",
      "148/148 - 139s - loss: 0.0015 - accuracy: 0.8471 - val_loss: 0.5870 - val_accuracy: 0.7407\n",
      "Epoch 25/50\n",
      "148/148 - 139s - loss: 0.0015 - accuracy: 0.8340 - val_loss: 0.5762 - val_accuracy: 0.7078\n",
      "Epoch 26/50\n",
      "148/148 - 142s - loss: 0.0020 - accuracy: 0.8271 - val_loss: 0.5586 - val_accuracy: 0.7269\n",
      "Epoch 27/50\n",
      "148/148 - 142s - loss: 0.0019 - accuracy: 0.8305 - val_loss: 0.5830 - val_accuracy: 0.7293\n",
      "Epoch 28/50\n",
      "148/148 - 142s - loss: 9.0117e-04 - accuracy: 0.8252 - val_loss: 0.6456 - val_accuracy: 0.7240\n",
      "Epoch 29/50\n",
      "148/148 - 141s - loss: 0.0011 - accuracy: 0.8376 - val_loss: 0.5751 - val_accuracy: 0.6940\n",
      "Epoch 30/50\n",
      "148/148 - 144s - loss: 0.0014 - accuracy: 0.8222 - val_loss: 0.5774 - val_accuracy: 0.7088\n",
      "Epoch 31/50\n",
      "148/148 - 143s - loss: 0.0023 - accuracy: 0.8659 - val_loss: 0.4936 - val_accuracy: 0.7531\n",
      "Epoch 32/50\n",
      "148/148 - 142s - loss: 0.0017 - accuracy: 0.8488 - val_loss: 0.5076 - val_accuracy: 0.7336\n",
      "Epoch 33/50\n",
      "148/148 - 141s - loss: 0.0011 - accuracy: 0.8385 - val_loss: 0.5665 - val_accuracy: 0.7235\n",
      "Epoch 34/50\n",
      "148/148 - 143s - loss: 9.0039e-04 - accuracy: 0.8421 - val_loss: 0.5844 - val_accuracy: 0.7345\n",
      "Epoch 35/50\n",
      "148/148 - 143s - loss: 5.4701e-04 - accuracy: 0.8449 - val_loss: 0.6814 - val_accuracy: 0.7479\n",
      "Epoch 36/50\n",
      "148/148 - 141s - loss: 6.2200e-04 - accuracy: 0.8294 - val_loss: 0.6359 - val_accuracy: 0.7479\n",
      "Epoch 37/50\n",
      "148/148 - 140s - loss: 0.0013 - accuracy: 0.8402 - val_loss: 0.6301 - val_accuracy: 0.7212\n",
      "Epoch 38/50\n",
      "148/148 - 139s - loss: 0.0020 - accuracy: 0.8515 - val_loss: 0.5924 - val_accuracy: 0.7364\n",
      "Epoch 39/50\n",
      "148/148 - 140s - loss: 0.0017 - accuracy: 0.8437 - val_loss: 0.5773 - val_accuracy: 0.7316\n",
      "Epoch 40/50\n",
      "148/148 - 140s - loss: 0.0010 - accuracy: 0.8472 - val_loss: 0.5593 - val_accuracy: 0.7112\n",
      "Epoch 41/50\n",
      "148/148 - 140s - loss: 9.1242e-04 - accuracy: 0.8371 - val_loss: 0.6069 - val_accuracy: 0.7173\n",
      "Epoch 42/50\n",
      "148/148 - 141s - loss: 7.6914e-04 - accuracy: 0.8320 - val_loss: 0.5906 - val_accuracy: 0.7088\n",
      "Epoch 43/50\n",
      "148/148 - 143s - loss: 3.5687e-04 - accuracy: 0.8486 - val_loss: 0.6644 - val_accuracy: 0.7140\n",
      "Epoch 44/50\n",
      "148/148 - 141s - loss: 7.3906e-04 - accuracy: 0.8534 - val_loss: 0.6756 - val_accuracy: 0.7240\n",
      "Epoch 45/50\n",
      "148/148 - 143s - loss: 0.0012 - accuracy: 0.8343 - val_loss: 0.6832 - val_accuracy: 0.7278\n",
      "Epoch 46/50\n",
      "148/148 - 142s - loss: 6.8633e-04 - accuracy: 0.8291 - val_loss: 0.5728 - val_accuracy: 0.7097\n",
      "Epoch 47/50\n",
      "148/148 - 141s - loss: 5.2847e-04 - accuracy: 0.8166 - val_loss: 0.7396 - val_accuracy: 0.7159\n",
      "Epoch 48/50\n",
      "148/148 - 142s - loss: 4.1944e-04 - accuracy: 0.8304 - val_loss: 0.7516 - val_accuracy: 0.7269\n",
      "Epoch 49/50\n",
      "148/148 - 140s - loss: 2.6908e-04 - accuracy: 0.8282 - val_loss: 0.7956 - val_accuracy: 0.7255\n",
      "Epoch 50/50\n",
      "148/148 - 139s - loss: 6.6566e-04 - accuracy: 0.8344 - val_loss: 0.7444 - val_accuracy: 0.7274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5e56f53278>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DNN.fit(convert_sparse_matrix_to_sparse_tensor(X_train_tfidf), y_train,\n",
    "                              validation_data=(convert_sparse_matrix_to_sparse_tensor(X_test_tfidf), y_val),\n",
    "                              epochs=50,\n",
    "                              batch_size=128, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DY6iCkHs9QjM",
    "outputId": "b6c297b1-8bd3-4efd-c8a7-c7c90029bd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.8255351392309148\n",
      "Accuracy 0.6825548141086749\n"
     ]
    }
   ],
   "source": [
    "# make predictions for validation set\n",
    "y_pred = model_DNN.predict(convert_sparse_matrix_to_sparse_tensor(X_test_tfidf))\n",
    "# evaluate performance\n",
    "\n",
    "print('F1 score',f1_score(np.where(y_pred>0.5,1,0), y_val, average=\"micro\"))\n",
    "print('Accuracy',accuracy_score(np.where(y_pred>0.5,1,0), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCI2i3SEqjhX"
   },
   "outputs": [],
   "source": [
    "def call_test_data():\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    test_df['merged'] = test_df['TITLE'] + ' ' + test_df['ABSTRACT']\n",
    "    test_df['merged'] = test_df['merged'].apply(lambda x: PreProcessing(x))\n",
    "    \n",
    "    test_df_new = test_df['merged']\n",
    "    return test_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZgU5G78gBTAw",
    "outputId": "d62e5ed6-06b8-46af-e063-9ebe707b6342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    closed form marginal likelihood gamma poisson ...\n",
       "1    laboratory mid ir spectra equilibrated igneous...\n",
       "2    case static amsdu aggregation wlans frame aggr...\n",
       "3    gaia eso survey inner disk intermediate age op...\n",
       "4    witness functions versus interpretation functi...\n",
       "Name: merged, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = call_test_data()\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rv_poQmkB3we"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf,data_test_tfidf = TFIDF(x_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "74gYha_hCSWT",
    "outputId": "50f583c4-bd05-47e2-cc06-aa8ff6fc1549"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8568201e-04, 4.7665688e-07, 8.6992979e-04, 9.9999714e-01,\n",
       "        8.8609740e-06, 3.0741769e-06],\n",
       "       [3.1563552e-15, 1.0000000e+00, 1.7303320e-11, 9.1336140e-12,\n",
       "        4.5173718e-16, 1.8739562e-15],\n",
       "       [9.4533801e-01, 1.0934740e-02, 1.7881483e-02, 9.3039739e-01,\n",
       "        2.1320879e-02, 7.7667832e-04],\n",
       "       ...,\n",
       "       [8.4806424e-01, 1.7060608e-02, 9.7885132e-03, 4.8203889e-01,\n",
       "        9.3704498e-01, 5.2706152e-02],\n",
       "       [4.1578114e-03, 2.0454491e-09, 3.6415458e-04, 1.0000000e+00,\n",
       "        7.5976828e-08, 1.9849957e-09],\n",
       "       [9.9870443e-01, 9.2247128e-04, 1.0570288e-03, 4.0677190e-03,\n",
       "        5.4152541e-05, 4.2409642e-06]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions for validation set\n",
    "y_test_pred = model_DNN.predict(convert_sparse_matrix_to_sparse_tensor(data_test_tfidf))\n",
    "# evaluate performance\n",
    "y_test_pred\n",
    "# print('F1 score',f1_score(np.where(y_pred>0.5,1,0), y_val, average=\"micro\"))\n",
    "# print('Accuracy',accuracy_score(np.where(y_pred>0.5,1,0), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "7KN_Qlc2BS8_",
    "outputId": "f3434be4-c700-40eb-f68c-c272262a6678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = np.where(y_test_pred>0.5, 1,0)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EwM-Kvy1BS3W",
    "outputId": "e16ae361-b877-4f82-9487-4332ab1dba00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science  Physics  ...  Quantitative Biology  Quantitative Finance\n",
       "0                 0        0  ...                     0                     0\n",
       "1                 0        1  ...                     0                     0\n",
       "2                 1        0  ...                     0                     0\n",
       "3                 0        1  ...                     0                     0\n",
       "4                 1        0  ...                     0                     0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = pd.DataFrame(y_test_pred, columns = ['Computer Science', 'Physics', 'Mathematics', 'Statistics',\n",
    "       'Quantitative Biology', 'Quantitative Finance'])\n",
    "ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxpgRlzNBSwW"
   },
   "outputs": [],
   "source": [
    "ans.to_csv('submissionv26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ttq5m7oqjZu"
   },
   "outputs": [],
   "source": [
    "# Got 0.834 f1_score on testing data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nlp_ann_multilabel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
